[titan]
modelId = amazon.titan-tg1-large
accept = application/json
contentType = application/json
body_config = {"inputText": "{prompt}", "textGenerationConfig": {"maxTokenCount":512,"stopSequences":[],"temperature":0,"topP":0.9}}
 
 
[claude]
modelId = anthropic.claude-v2
accept = */*
contentType = application/json
body_config = {"prompt": "{prompt}", "max_tokens_to_sample":300,"temperature":1,"top_k":250,"top_p":0.999,"stop_sequences":[]}


[jurassic]
modelId = ai21.j2-ultra
accept = */*
contentType = application/json
body_config = {"prompt":"{prompt}","maxTokens":200,"temperature":0,"topP":1,"stopSequences":[],"countPenalty":{"scale":0},"presencePenalty":{"scale":0},"frequencyPenalty":{"scale":0}}


[cohere]
modelId = cohere.command-text-v14
accept = */*
contentType = application/json
body_config = {"prompt": "{prompt}","max_tokens": 100,"temperature": 0.8} 


[llama]
modelId = meta.llama2-13b-chat-v1
accept = */*
contentType = application/json
body_config = {"prompt": "{prompt}","max_gen_len": 512,"temperature": 0.2,"top_p": 0.9}
